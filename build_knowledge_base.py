import os
from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader, UnstructuredWordDocumentLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores import FAISS

# --- é…ç½®å‚æ•° ---
KNOWLEDGE_DIR = "./knowledge_base"
FAISS_INDEX_PATH = "./faiss_jinlei_index"
OLLAMA_EMBEDDING_MODEL = "m3e-base" # è¯·ç¡®ä¿å·²é€šè¿‡ ollama pull m3e-base æ‹‰å–

def build_index():
    """
    åŠ è½½ã€åˆ‡åˆ†æ–‡æ¡£ï¼Œåˆ›å»ºå¹¶ä¿å­˜ FAISS å‘é‡çŸ¥è¯†åº“ã€‚
    """
    # 1. æ–‡æ¡£åŠ è½½
    print(f"--- 1. æ­£åœ¨åŠ è½½ {KNOWLEDGE_DIR} ä¸­çš„æ–‡æ¡£... ---")
    
    # å®šä¹‰åŠ è½½å™¨æ˜ å°„
    loader_mapping = {
        ".pdf": PyPDFLoader,
        ".docx": UnstructuredWordDocumentLoader,
    }
    
    # ä½¿ç”¨ DirectoryLoader æ‰¹é‡åŠ è½½
    loader = DirectoryLoader(
        KNOWLEDGE_DIR, 
        loader_map=loader_mapping,
        silent_errors=True,
        # ç¡®ä¿ loader èƒ½å¤Ÿå¤„ç†åµŒå¥—æ–‡ä»¶å¤¹
        glob="**/*",
        # é’ˆå¯¹ä¸­æ–‡æ–‡æ¡£ï¼Œç¡®ä¿ç¼–ç æ­£ç¡®
        loader_kwargs={'autodetect_encoding': True} 
    )
    
    try:
        documents = loader.load()
        if not documents:
            print("âŒ è­¦å‘Šï¼šæœªæ‰¾åˆ°ä»»ä½•æ”¯æŒæ ¼å¼çš„æ–‡æ¡£ï¼Œè¯·æ£€æŸ¥çŸ¥è¯†åº“æ–‡ä»¶å¤¹ã€‚")
            return
        print(f"âœ… æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£é¡µé¢/å—ã€‚")
    except Exception as e:
        print(f"âŒ æ–‡æ¡£åŠ è½½å¤±è´¥: {e}")
        return

    # 2. æ–‡æœ¬åˆ‡åˆ†
    print("--- 2. æ­£åœ¨è¿›è¡Œæ–‡æœ¬åˆ‡åˆ†... ---")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", " ", ""] # ä¼˜åŒ–ä¸­æ–‡åˆ†éš”ç¬¦
    )
    texts = text_splitter.split_documents(documents)
    print(f"âœ… æ–‡æ¡£åˆ‡åˆ†æˆ {len(texts)} ä¸ªçŸ¥è¯†å—ã€‚")

    # 3. å‘é‡åŒ–ä¸çŸ¥è¯†åº“æ„å»º
    print(f"--- 3. æ­£åœ¨åˆå§‹åŒ– Embedding æ¨¡å‹ ({OLLAMA_EMBEDDING_MODEL}) å¹¶æ„å»º FAISS ç´¢å¼•... ---")
    
    embeddings = OllamaEmbeddings(
        model=OLLAMA_EMBEDDING_MODEL,
        base_url="http://localhost:11434" # ç¡®ä¿ Ollama æœåŠ¡åœ°å€æ­£ç¡®
    )
    
    try:
        db = FAISS.from_documents(texts, embeddings)
        
        # 4. ä¿å­˜ FAISS ç´¢å¼•
        db.save_local(FAISS_INDEX_PATH)
        print(f"âœ… FAISS ç´¢å¼•å·²æˆåŠŸä¿å­˜åˆ°: {FAISS_INDEX_PATH}")
        print("\nğŸ‰ çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼ç°åœ¨å¯ä»¥è¿è¡Œ Web åº”ç”¨äº†ã€‚")
    except Exception as e:
        print(f"âŒ å‘é‡åŒ–æˆ– FAISS çŸ¥è¯†åº“æ„å»ºå¤±è´¥: {e}")


if __name__ == "__main__":
    if not os.path.exists(KNOWLEDGE_DIR):
        print(f"åˆ›å»ºçŸ¥è¯†åº“ç›®å½•: {KNOWLEDGE_DIR}")
        os.makedirs(KNOWLEDGE_DIR)
        print("è¯·å°† PDF/Word æ–‡æ¡£æ”¾å…¥æ­¤ç›®å½•åï¼Œé‡æ–°è¿è¡Œæœ¬è„šæœ¬ã€‚")
    else:
        build_index()

# è¿è¡Œå‘½ä»¤: python build_knowledge_base.py
